{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train level 0: Logistic model\n",
    "- Optimize linear models for training on brand / device\n",
    "- V1: Select best data for model (onehotencoded both, separate, or just one)\n",
    "    - Brands onehot, device label: 2.40215702862 (five seeds: 2.4017680305744418)\n",
    "    - Seperate onehot encoded:  2.39089229204 (five seeds: 2.3901993860642716)\n",
    "    - Combined onehot encoded: 2.39583615824 (five seeds: 2.3952347531028977)\n",
    "- V2: Used couple of creative features based on brand and device model, also included brand when encoded device\n",
    "    - Without scaler: 2.39122949113 (five seeds: 2.3904997299834445)\n",
    "    - With scaler: 2.39075599796 (five seeds: 2.3899157753336815)\n",
    "- V3: Used a new CV standard used by all models\n",
    "    - CV Score: LB Score: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './data_ori/'\n",
    "feat_dir = './data/'\n",
    "sub_dir = './model_0_logistic'\n",
    "use_scaler = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def open_feature_file(fname, samples='train'):\n",
    "    if fname[-3:] == 'csv':\n",
    "        if samples=='train':\n",
    "            X = gatrain[['device_id']].merge( pd.read_csv(os.path.join(feat_dir, fname)), on='device_id', how='left')\n",
    "        else:\n",
    "            X = gatest[['device_id']].merge( pd.read_csv(os.path.join(feat_dir, fname)), on='device_id', how='left')\n",
    "            \n",
    "        X.drop('device_id', axis=1, inplace=True)\n",
    "        X.fillna(0, inplace=True)\n",
    "        \n",
    "        if use_scaler:\n",
    "            for c in X.columns:\n",
    "                if X[c].max()>1:\n",
    "                    X[c] = MinMaxScaler().fit_transform(X)\n",
    "            \n",
    "        #print X.shape\n",
    "        return csr_matrix(X.values)\n",
    "    else:\n",
    "        # Assume it is a pickle file\n",
    "        with open(os.path.join(feat_dir, '{}_{}.pickle'.format(fname,samples)), 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "            \n",
    "feature_files = ['features_brand_bag',\n",
    "                 'features_brand_model_bag',\n",
    "                 'features_brand_model.csv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gatrain = pd.read_csv('./data_ori/gender_age_train.csv')\n",
    "gatest = pd.read_csv('./data_ori/gender_age_test.csv')\n",
    "#train = pd.merge(gatrain, brand, on='device_id', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain = hstack([open_feature_file(f) for f in feature_files], format='csr')\n",
    "Xtest = hstack([open_feature_file(f,'test') for f in feature_files], format='csr')\n",
    "y = gatrain['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (74645, 1803)\n",
      "y (74645,)\n"
     ]
    }
   ],
   "source": [
    "print 'X', Xtrain.shape\n",
    "print 'y', y.shape\n",
    "#X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "letarget = LabelEncoder().fit(y)\n",
    "y = letarget.transform(y)\n",
    "n_classes = len(letarget.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load CV sets\n",
    "train_cv = pd.read_csv(os.path.join(data_dir, 'gender_age_train_cv.csv'))\n",
    "test_cv = pd.read_csv(os.path.join(data_dir, 'gender_age_test_cv.csv'))\n",
    "\n",
    "X_train, X_val = Xtrain[train_cv.sample_nr.values, :], Xtrain[test_cv.sample_nr.values, :]\n",
    "y_train, y_val = y[train_cv.sample_nr], y[test_cv.sample_nr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Linear regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'StratifiedKFold' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-aa62c6c51ec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Hyperparameter optimizatio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m123\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mkf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_folds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'StratifiedKFold' is not defined"
     ]
    }
   ],
   "source": [
    "# Hyperparameter optimizatio\n",
    "rs = 123\n",
    "kf = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=rs)\n",
    "\n",
    "log = LogisticRegression()\n",
    "param_grid = {'C': np.linspace(0.07, 0.20, 10), 'penalty': ['l2']}\n",
    "clf = GridSearchCV(log, param_grid, scoring='log_loss', n_jobs=5, cv=kf, verbose=10)\n",
    "clf.fit(Xtrain, y)\n",
    "print(\"Best score:{} with scorer {}\".format(clf.best_score_, clf.scorer_))\n",
    "print \"With parameters:\"\n",
    "    \n",
    "best_parameters = clf.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print '\\t%s: %r' % (param_name, best_parameters[param_name]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'type': 'LogisticRegression',\n",
    "         'C': 0.13,\n",
    "         'penalty': 'l2'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n",
      "2.39027660069\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n",
      "2.39035856141\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n",
      "2.39075599796\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n",
      "2.39049377478\n",
      "1 / 10\n",
      "2 / 10\n",
      "3 / 10\n",
      "4 / 10\n",
      "5 / 10\n",
      "6 / 10\n",
      "7 / 10\n",
      "8 / 10\n",
      "9 / 10\n",
      "10 / 10\n",
      "2.39079749726\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "models = {}\n",
    "for s in [0, 12, 123, 1234, 12345]:\n",
    "    kf = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=s)\n",
    "    pred_l = np.zeros((Xtrain.shape[0],n_classes))\n",
    "    c=1\n",
    "    for itrain, itest in kf:\n",
    "        print('%d / %d' % (c, 10))\n",
    "        ytrain, ytest = y[itrain], y[itest]\n",
    "        xg_train = Xtrain[itrain, :]\n",
    "        xg_test = Xtrain[itest, :]\n",
    "        clf = LogisticRegression(C=0.13, penalty='l2')\n",
    "        clf.fit(xg_train, ytrain)\n",
    "        pred_l[itest,:] = clf.predict_proba(xg_test)\n",
    "        c+=1\n",
    "    print log_loss(y, pred_l)\n",
    "    scores[s] = pred_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3899157753336815"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y,sum(scores.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.39050541479\n",
    "0.1\n",
    "2.39059357843\n",
    "0.115\n",
    "2.39044702338\n",
    "0.13\n",
    "2.39044648731\n",
    "0.145\n",
    "2.39028745599\n",
    "0.16\n",
    "2.39015495289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13\n",
      "2.39044648731\n",
      "0.145\n",
      "2.39028745599\n",
      "0.16\n",
      "2.39015495289\n",
      "0.175\n"
     ]
    }
   ],
   "source": [
    "n_models = 5\n",
    "\n",
    "scores = []\n",
    "models = []\n",
    "preds = []\n",
    "for c in np.linspace(0.13, 0.19, n_models):\n",
    "    print c\n",
    "    \n",
    "    params = {'type': 'LogisticRegression',\n",
    "              'C': c,\n",
    "              'penalty': 'l2',\n",
    "              'solver': 'lbfgs',\n",
    "              'max_iter': 100000,\n",
    "              'warm_start': False}\n",
    "    \n",
    "    clf = LogisticRegression(C=c, \n",
    "                             penalty='l2', \n",
    "                             max_iter=100000, \n",
    "                             warm_start=False,\n",
    "                             solver='lbfgs')\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    clf = LogisticRegression(C=c, \n",
    "                             penalty='l2', \n",
    "                             max_iter=100000, \n",
    "                             warm_start=True,\n",
    "                             solver='lbfgs')\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    pred = clf.predict_proba(X_val)\n",
    "    score = log_loss(y_val, pred)\n",
    "    print score\n",
    "    \n",
    "    model_out = {'model': clf,\n",
    "                 'score': score,\n",
    "                 'params': params}\n",
    "    \n",
    "    models.append(model_out)\n",
    "    scores.append(score)\n",
    "    preds.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score: 2.3903\n"
     ]
    }
   ],
   "source": [
    "cv_score = log_loss(y_val, sum(preds)/n_models)\n",
    "print('CV score: {:.4f}'.format(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputfile = 'models_logistic_0_V3_{}_{:.4f}_{:.4f}.pickle'.format(datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\"),\n",
    "                                                                cv_score,\n",
    "                                                                -1.)\n",
    "\n",
    "output = {'script': 'train_model_0_logistic',\n",
    "          'model_params': params,\n",
    "          'no_models': 5,\n",
    "          'cross_validation': {'type': 'gender_age_train_cv.csv'},\n",
    "          'models': models}\n",
    "\n",
    "\n",
    "with open(os.path.join(sub_dir, outputfile), 'wb') as f:\n",
    "    pickle.dump(output,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### HyperOpt Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
