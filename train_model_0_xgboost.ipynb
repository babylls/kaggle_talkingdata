{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train level 0: XGBoost model\n",
    "\n",
    "- V1:Optimize xgboost for training on brand / device\n",
    "    - Alpha: increases for alpha value 1 to 5 and from 0.1 to 0.9, 0 is best value\n",
    "    - Lambda: decreases for [-0.05, 0,  0.05, 0.1, 0.2, 0.5, 1, 2, 5], it decreases after five: [6, 7, 8, 10, 12, 15, 20]. 6.2 optimal 2.39044903984\n",
    "    - Number rounds: 25, 50, 75, 100: increases with number of rounds, 75 seems optimal\n",
    "    - Select best data for model (onehotencoded both, separate, or just one)\n",
    "        - Brands onehot, device label: 2.4304884100135387\n",
    "        - Seperate onehot encoded: 2.3946668507651609 (requires regularization)\n",
    "        - Combined onehot encoded: 2.402189399699036\n",
    "- V2: Used couple of creative features based on brand and device model, also included brand when encoded device\n",
    "    - Without scaler: 2.38983383101\n",
    "    - With scaler: 2.3901336994178406\n",
    "    - Alpha: score decreases, but train score decreases further, so less overfitting\n",
    "    - Lambda: score decreases, but train score decreases further, so less overfitting (less dramatic than alpha)\n",
    "    - Weet niet waar ik ga aan doen: ga maar voor gemiddeld: alpha: 1, lambda: 3\n",
    "- V3: Generated five different models with different seeds without scaler and first 1800 features\n",
    "    - CV Score: 2.3905, LB Score: 2.39022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from ml_toolbox.kaggle import KaggleResult\n",
    "\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preparing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = './data_ori/'\n",
    "feat_dir = './data/'\n",
    "sub_dir = './model_0_xgboost'\n",
    "\n",
    "description = 'models_xgboost_0_V3'\n",
    "\n",
    "use_scaler = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_feature_file(fname, samples='train'):\n",
    "    if fname[-3:] == 'csv':\n",
    "        if samples=='train':\n",
    "            X = gatrain[['device_id']].merge( pd.read_csv(os.path.join(feat_dir, fname)), on='device_id', how='left')\n",
    "        else:\n",
    "            X = gatest[['device_id']].merge( pd.read_csv(os.path.join(feat_dir, fname)), on='device_id', how='left')\n",
    "            \n",
    "        X.drop('device_id', axis=1, inplace=True)\n",
    "        X.fillna(0, inplace=True)\n",
    "        \n",
    "        if use_scaler:\n",
    "            for c in X.columns:\n",
    "                if X[c].max()>1:\n",
    "                    X[c] = StandardScaler().fit_transform(X)\n",
    "            \n",
    "        #print X.shape\n",
    "        return csr_matrix(X.values)\n",
    "    else:\n",
    "        # Assume it is a pickle file\n",
    "        with open(os.path.join(feat_dir, '{}_{}.pickle'.format(fname,samples)), 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "            \n",
    "feature_files = ['features_brand_bag',\n",
    "                 'features_brand_model_bag',\n",
    "                 'features_brand_model.csv']\n",
    "\n",
    "# Which features\n",
    "n_features = range(1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gatrain = pd.read_csv('./data_ori/gender_age_train.csv')\n",
    "gatest = pd.read_csv('./data_ori/gender_age_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xtrain = hstack([open_feature_file(f) for f in feature_files], format='csr')\n",
    "Xtest = hstack([open_feature_file(f,'test') for f in feature_files], format='csr')\n",
    "y = gatrain['group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xtrain = Xtrain[:, n_features]\n",
    "Xtest = Xtest[:, n_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "letarget = LabelEncoder().fit(gatrain.group.values)\n",
    "y = letarget.transform(gatrain.group.values)\n",
    "n_classes = len(letarget.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load CV sets\n",
    "train_cv = pd.read_csv(os.path.join(data_dir, 'gender_age_train_cv.csv'))\n",
    "test_cv = pd.read_csv(os.path.join(data_dir, 'gender_age_test_cv.csv'))\n",
    "\n",
    "X_train, X_val = Xtrain[train_cv.sample_nr.values, :], Xtrain[test_cv.sample_nr.values, :]\n",
    "y_train, y_val = y[train_cv.sample_nr], y[test_cv.sample_nr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (67229, 1800) X_val: (7416, 1800)\n",
      "y_train (67229,) y_val (7416,)\n"
     ]
    }
   ],
   "source": [
    "print 'X_train', X_train.shape, 'X_val:', X_val.shape\n",
    "print 'y_train', y_train.shape, 'y_val', y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.481582\tval-mlogloss:2.481968\n",
      "[50]\ttrain-mlogloss:2.402277\tval-mlogloss:2.411722\n",
      "[100]\ttrain-mlogloss:2.379335\tval-mlogloss:2.395078\n",
      "[150]\ttrain-mlogloss:2.369483\tval-mlogloss:2.389797\n",
      "[200]\ttrain-mlogloss:2.364329\tval-mlogloss:2.387778\n",
      "[249]\ttrain-mlogloss:2.361276\tval-mlogloss:2.386955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score on 6598: 2.3870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.481571\tval-mlogloss:2.481990\n",
      "[50]\ttrain-mlogloss:2.401988\tval-mlogloss:2.413305\n",
      "[100]\ttrain-mlogloss:2.378865\tval-mlogloss:2.397761\n",
      "[150]\ttrain-mlogloss:2.369007\tval-mlogloss:2.393200\n",
      "[200]\ttrain-mlogloss:2.363744\tval-mlogloss:2.391690\n",
      "[249]\ttrain-mlogloss:2.360715\tval-mlogloss:2.391236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score on 8999: 2.3912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.481572\tval-mlogloss:2.482058\n",
      "[50]\ttrain-mlogloss:2.401570\tval-mlogloss:2.415254\n",
      "[100]\ttrain-mlogloss:2.378293\tval-mlogloss:2.400645\n",
      "[150]\ttrain-mlogloss:2.368340\tval-mlogloss:2.396770\n",
      "[200]\ttrain-mlogloss:2.363139\tval-mlogloss:2.395773\n",
      "[249]\ttrain-mlogloss:2.360070\tval-mlogloss:2.395693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score on 20347: 2.3957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.481569\tval-mlogloss:2.481998\n",
      "[50]\ttrain-mlogloss:2.401962\tval-mlogloss:2.412853\n",
      "[100]\ttrain-mlogloss:2.379029\tval-mlogloss:2.396592\n",
      "[150]\ttrain-mlogloss:2.369150\tval-mlogloss:2.391467\n",
      "[200]\ttrain-mlogloss:2.363961\tval-mlogloss:2.389560\n",
      "[249]\ttrain-mlogloss:2.360815\tval-mlogloss:2.388834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score on 12690: 2.3888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:2.481554\tval-mlogloss:2.481987\n",
      "[50]\ttrain-mlogloss:2.402125\tval-mlogloss:2.412875\n",
      "[100]\ttrain-mlogloss:2.379049\tval-mlogloss:2.396916\n",
      "[150]\ttrain-mlogloss:2.369217\tval-mlogloss:2.392071\n",
      "[200]\ttrain-mlogloss:2.364056\tval-mlogloss:2.390374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score on 73471: 2.3898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[249]\ttrain-mlogloss:2.360983\tval-mlogloss:2.389785\n"
     ]
    }
   ],
   "source": [
    "n_models = 5\n",
    "\n",
    "scores = []\n",
    "models_out = []\n",
    "\n",
    "for s in np.random.randint(99999,size=n_models):\n",
    "    \n",
    "    kf = list(StratifiedKFold(y, n_folds=10, shuffle=True, random_state=s))[0]\n",
    "\n",
    "    Xtr, Xte = Xtrain[kf[0], :], Xtrain[kf[1], :]\n",
    "    ytr, yte = y[kf[0]], y[kf[1]]\n",
    "    \n",
    "    params = {\n",
    "            \"objective\": \"multi:softprob\",\n",
    "            'booster': 'gblinear',\n",
    "            'num_class': 12,\n",
    "            \"eta\": 0.01,\n",
    "            \"silent\": 1,\n",
    "            'alpha':1,\n",
    "            'lambda': 3,\n",
    "            'n_estimators': 250,\n",
    "            'seed': s,\n",
    "            'eval_metric': 'mlogloss'\n",
    "        }\n",
    "    \n",
    "    xg_train = xgb.DMatrix(Xtr, label=ytr)\n",
    "    xg_val = xgb.DMatrix(Xte, label=yte)\n",
    "    \n",
    "    watchlist = [ (xg_train,'train'), (xg_val, 'val') ]\n",
    "    \n",
    "    clf = xgb.train(params, xg_train, params['n_estimators'], watchlist, verbose_eval=50 )\n",
    "    \n",
    "    pred_val = clf.predict(xg_val)\n",
    "    \n",
    "    score = log_loss(yte, pred_val)\n",
    "    \n",
    "    print('Validation score on {}: {:.4f}'.format(s, score))\n",
    "\n",
    "    model_out = {'model': clf,\n",
    "                 'score': score,\n",
    "                 'params': params}\n",
    "    \n",
    "    models_out.append(model_out)\n",
    "    scores.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Score: 2.3905\n"
     ]
    }
   ],
   "source": [
    "cv_score = np.mean(scores)\n",
    "print('CV Score: {:.4f}'.format(cv_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload result to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "scores = []\n",
    "for m in models_out:\n",
    "    clf = m['model']\n",
    "    \n",
    "    pred = clf.predict(xgb.DMatrix(Xtest))\n",
    "    \n",
    "    preds.append(pred)\n",
    "    \n",
    "pred_test = sum(preds)/len(models_out)\n",
    "\n",
    "pred = pd.DataFrame(pred, index = gatest.device_id, columns=letarget.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "kag = KaggleResult(pred.values, \n",
    "                   pred.index.values, \n",
    "                   cv_score=cv_score, \n",
    "                   description=description, \n",
    "                   subdir=sub_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.39022\n"
     ]
    }
   ],
   "source": [
    "if kag.validate():\n",
    "    kag.upload()\n",
    "print kag.lb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Store models..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputfile = '{}_{}_{:.4f}_{:.4f}.pickle'.format(description, \n",
    "                                                 datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\"),\n",
    "                                                 cv_score,\n",
    "                                                 kag.lb_score)\n",
    "\n",
    "output = {'script': 'train_model_0_xgboost',\n",
    "          'features': n_features,\n",
    "          'feature_sets': feature_files,\n",
    "          'model_params': params,\n",
    "          'no_models': 5,\n",
    "          'cross_validation': {'type': 'randomsplit_0.1'},\n",
    "          'models': models_out}\n",
    "\n",
    "\n",
    "with open(os.path.join(sub_dir, outputfile), 'wb') as f:\n",
    "    pickle.dump(output,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Below is WIP...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for a in np.linspace(3,6,3):\n",
    "    params = {\n",
    "        \"objective\": \"multi:softprob\",\n",
    "        'booster': 'gblinear',\n",
    "        'num_class': 12,\n",
    "        \"eta\": 0.01,\n",
    "        \"silent\": 1,\n",
    "        'alpha':1,\n",
    "        'lambda': a,\n",
    "        'n_estimators': 250,\n",
    "        'eval_metric': 'mlogloss'\n",
    "    }\n",
    "    kf = StratifiedKFold(y, n_folds=10, shuffle=True, random_state=0)\n",
    "    pred = np.zeros((Xtrain.shape[0],n_classes))\n",
    "    for itrain, itest in kf:\n",
    "        ytrain, ytest = y[itrain], y[itest]\n",
    "        xg_train = xgb.DMatrix( Xtrain[itrain, :], label=ytrain)\n",
    "        xg_test = xgb.DMatrix(Xtrain[itest, :], label=ytest)\n",
    "        watchlist = [ (xg_train,'train'), (xg_test, 'test') ]\n",
    "        bst = xgb.train(params, xg_train, params['n_estimators'], watchlist, verbose_eval=50 )\n",
    "        pred[itest,:] = bst.predict(xg_test)\n",
    "    print a,':',log_loss(y, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log_loss(y, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
