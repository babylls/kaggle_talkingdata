{"cells":[
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\npd.options.display.float_format = '{:.2f}'.format\ndatadir = '../input/'\n\n\ndef describe(df):\n    des = df.describe(include='all')\n    des.drop('25%',inplace=True)\n    des.drop('50%',inplace=True)\n    des.drop('75%',inplace=True)\n    des.loc['nans'] = np.sum(df.isnull())\n    \n    return des\n   \ndef unique_values(df, col, outputtype='str_rel', col_group=None, top=None):\n    \n    if col_group is None: col_group = col\n    \n    \n    counts = df.groupby([col_group])[col].count().sort_values(ascending=False)\n    \n    if top is not None:\n        freq_other = sum(counts[top:])\n        counts = counts[:top]\n        counts['Other'] = freq_other\n\n    if outputtype == 'series':\n        return counts\n    elif outputtype == \"str_abs\":\n        return ', '.join([str(i)+' (' + str(v) + ')' for (i,v) in counts.iteritems()])\n    elif outputtype == 'str_rel':\n        return ', '.join([str(i)+' (' + '{:.0f}%'.format(float(v)/len(df)*100) + ')' for (i,v) in counts.iteritems()])\n    elif outputtype == \"analysis\":\n        return '%d unique values, freq. min: %d (%s), freq. max: %d (%s), freq. median: %d' % (len(counts), counts.min(),counts.idxmin(), counts.max(), counts.idxmax(), np.median(counts) )\n\ndef check_relation(df1, df2, col_key1, col_key2=None):\n    \n    if col_key2 is None: col_key2 = col_key1\n    \n    print(\"Number of rows in 1: %d\" % df1.shape[0])\n    print(\"Number of rows in 2: %d\" % df2.shape[0])\n    print(\"Unique keys in 1: %d\" % len(set(df1[col_key1])))\n    print(\"Unique keys in 2: %d\" % len(set(df2[col_key2])))\n    print(\"Key coverage 1 by 2: %f\" % ( float(len(set(df1[col_key1]) & set(df2[col_key2]))) / len(set(df1[col_key1])) ))\n    print(\"Key coverage 2 by 1: %f\" % ( float(len(set(df1[col_key1]) & set(df2[col_key2]))) / len(set(df2[col_key2])) ))\n    \n    # To calculate row coverage, do a count per key first\n    count1 = df1.groupby([col_key1])[col_key1].count()\n    count2 = df2.groupby([col_key2])[col_key2].count()\n    sum_count1 = float( count1.loc[set(df2[col_key2])].sum() )\n    sum_count2 = float( count2.loc[set(df1[col_key1])].sum() )\n    print(\"Row coverage 1 by 2: %f\" % ( sum_count1 / df1.shape[0] ))\n    print(\"Row coverage 2 by 1: %f\" % ( sum_count2 / df2.shape[0] ))\n        \n        \ndef plot_distribution(df, col, split_col):\n    # REMARK: ONLY WORKS FOR SPLIT_COL HAVING TWO UNIQUE VALUES\n    \n    u_s = df[split_col].unique()    \n    \n    df0 = df[df[split_col]==u_s[0]]\n    df1 = df[df[split_col]==u_s[1]]\n    \n    col_0 = sorted(df0[col].unique())\n    col_1 = sorted(df1[col].unique())\n    \n    cnt_df0 = df0[col].value_counts()\n    cnt_cf1 = df1[col].value_counts()\n    \n    \n    width = 0.4\n    indm = np.arange(len(col_0))\n    indf = np.arange(len(col_1))\n    plt.figure()\n    plt.title('Distribution of ' + str(col) + ' by ' + str(split_col))\n    plt.bar(indm+width/2, cnt_df0, width, color='b')\n    plt.bar(indf+1.5*width, cnt_cf1, width, color='r')\n    plt.xlim([0,6+width/2])\n    plt.xticks(np.concatenate([indm+width,indf+2*width]),np.concatenate([col_0,col_1]),rotation='vertical')\n    plt.tight_layout()\n    plt.legend([str(x) for x in u_s])\n    plt.grid()\n    \n    ax = plt.gca()\n    rects = ax.patches\n    scores = np.concatenate([cnt_df0,cnt_cf1]).astype(float)/len(df)*100\n    for rect, label in zip(rects, scores):\n        height = rect.get_height()\n        ax.text(rect.get_x() + rect.get_width()/2, height, \"{:.0f}%\".format(label), ha='center', va='bottom')\ndef inspect_gender_age():\n    \n    # To-do: inspect device-id\n    \n    print(\"Inspect table GENDER_AGE_TRAIN...\")\n    print(gender_age.head(5))\n    print(\"\")\n    print(describe(gender_age))\n    print(\"\")\n    print(\"Value counts age:\")\n    print(unique_values(gender_age, col='age', outputtype = 'str_abs'))\n    print(\"\")\n    print(\"Value counts gender:\")\n    print(unique_values(gender_age, col='gender', outputtype = 'str_rel'))\n    print(\"\")\n    print(\"Value counts group:\")\n    print(unique_values(gender_age, col='group', outputtype = 'str_rel'))\n    print(\"\")\n    plot_distribution(gender_age,col='group',split_col='gender')\n \ndef inspect_test():\n    print(\"Inspect table GENDER_AGE_TEST...\")\n    print(test.head(5))\n    print(\"Rows: %d\" % test.shape[0])\n    print(\"Unique device_id values: %d\" % len(test.device_id.unique()))\n   \ndef inspect_events():\n    print(\"Inspect table EVENTS...\")\n    print(events.head(5))\n    print(\"\")\n    print(describe(events))\n    \n    d=pd.DatetimeIndex(events.timestamp)\n    print(\"Value counts timestamp:\")\n    print(\"Per year:\")\n    print(unique_values(events,'timestamp',col_group=d.year,outputtype='str_rel'))\n    print(\"Per month:\")\n    print(unique_values(events,'timestamp',col_group=d.month,outputtype='str_rel'))\n    print(\"Per day:\")\n    print(unique_values(events,'timestamp',col_group=d.day,outputtype='str_rel'))\n    print(\"Per hour:\")\n    print(unique_values(events,'timestamp',col_group=d.hour,outputtype='str_rel'))\n    print(\"\")\n    \n    print(\"Rows: %d\" % events.shape[0])\n    print(\"Unique event_id values: %d\" % len(events.event_id.unique()))\n    print(\"Unique device_id values: %d\" % len(events.device_id.unique()))\n    print(\"Device_id: %s \" % unique_values(events, 'device_id', outputtype=\"analysis\"))\n    print(\"Device_id Top10: %s\" % unique_values(events, 'device_id', outputtype=\"str_abs\", top=10))\n    \ndef inspect_brands():\n    print(\"Inspect PHONE_BRAND_DEVICE_MODEL...\")\n    print(brands.head())\n    print(\"\")\n    print(describe(brands))\n    print(\"\")\n    \n    print(\"Rows: %d\" % brands.shape[0])\n    print(\"Unique device_id values: %d\" % len(brands.device_id.unique()))\n    print(\"Device_id Top10: %s\" % unique_values(brands, 'device_id', outputtype=\"str_abs\", top=10))\n    print(\"\")\n    print(\"Phone brands:\")\n    print(unique_values(brands, col='phone_brand', outputtype='analysis'))\n    print(unique_values(brands, col='phone_brand'))\n    print(\"Device models:\")\n    print(unique_values(brands, col='device_model', outputtype='analysis'))\n    print(unique_values(brands, col='device_model', top=25))\n    \ndef inspect_app_events():\n    print(\"Inspect APP_EVENTS...\")\n    print(app_events.head())\n    print(\"\")\n    print(describe(app_events))\n    print(\"\")\n    \n    print(\"Rows: %d\" % app_events.shape[0])\n    print(\"event_id: %s\" % unique_values(app_events, col='event_id', outputtype='analysis'))\n    print(\"app_id: %s\" % unique_values(app_events, col='app_id', outputtype='analysis'))\n    print(\"app_id top 25: %s\" % unique_values(app_events, col='app_id', top=25))\n    \ndef inspect_app_labels():\n    print(\"Inspect APP_LABELS...\")\n    print(app_labels.head())\n    print(\"\")\n    print(describe(app_labels))\n    print(\"\")\n    \n    print(\"Rows: %d\" % app_labels.shape[0])\n    print(\"app_id: %s\" % unique_values(app_labels, col='app_id', outputtype='analysis'))\n    print(\"label_id: %s\" % unique_values(app_labels, col='label_id', outputtype='analysis'))\n    \ndef inspect_label_categories():\n    print(\"Inspect LABEL_CATEGORIES...\")\n    print(app_cats.head())\n    print(\"\")\n    print(describe(app_cats))\n    print(\"\")\n    \n    print(\"Rows: %d\" % app_cats.shape[0])\n    print(\"label_id: %s\" % unique_values(app_cats, col='label_id', outputtype='analysis'))\n    print(\"category: %s\" % unique_values(app_cats, col='category', outputtype='analysis'))\n    print(\"category top-25: %s\" % unique_values(app_cats, col='category', top=25, outputtype='str_abs'))\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print('Read train...')\nc = {'decice_id': np.str, 'gender': np.str, 'age': np.int, 'group': np.str}\ngender_age = pd.read_csv(datadir + 'gender_age_train.csv', dtype=c)\n\ninspect_gender_age()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print('Read test...')\nc = {'decice_id': np.str}\ntest = pd.read_csv(datadir + 'gender_age_test.csv', dtype=c)\n\ninspect_test()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print(\"Reading events...\")\ndateparse = lambda x: pd.datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\nc = {'event_id': np.int64,'devide_id': np.str,'timestamp': np.object, 'longitude': np.float, 'latitude':np.float}\nevents=pd.read_csv(datadir + 'events.csv', dtype=c, parse_dates=['timestamp'], date_parser=dateparse)\n\ninspect_events()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print('Read brands...')\nc = {'decice_id': np.str, 'phone_brand': np.str, 'device_model': np.str}\nbrands = pd.read_csv(datadir + 'phone_brand_device_model.csv', dtype=c)\n\ninspect_brands()\n"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print('Read app events...')\nc = {'event_id': np.int64, 'app_id': np.int64, 'is_installed': np.int, 'is_active': np.int}\napp_events = pd.read_csv(datadir + 'app_events.csv', dtype=c)\n\ninspect_app_events()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print('Read app labels...')\nc = {'label_id': np.int64, 'app_id': np.int64}\napp_labels = pd.read_csv(datadir + 'app_labels.csv', dtype=c)\n\ninspect_app_labels()"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print('Read label categories...')\nc = {'label_id': np.int64, 'category': np.str}\napp_cats = pd.read_csv(datadir + 'label_categories.csv', dtype=c)\napp_cats.category.fillna('unknown',inplace=True)\n\ninspect_label_categories() "
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": "print('Checking relation GENDER_AGE and BRANDS')\ncheck_relation(gender_age, brands, 'device_id')\n\nprint('Checking relation TEST and BRANDS')\ncheck_relation(test, brands, 'device_id')\n\nprint('Checking relation GENDER_AGE and EVENTS')\ncheck_relation(gender_age, events, 'device_id')\n\nprint('Checking relation TEST and EVENTS')\ncheck_relation(test, events, 'device_id')\n\nprint('Checking relation EVENTS and APP_EVENTS')\ncheck_relation(events, app_events, 'event_id')\n\nprint('Checking relation APP_EVENTS and APP_LABELS')\ncheck_relation(app_events, app_labels, 'app_id')\n\nprint('Checking relation APP_LABELS and LABEL_CATEGORIES')\ncheck_relation(app_labels, app_cats, 'label_id')"
 },
 {
  "cell_type": "code",
  "execution_count": null,
  "metadata": {
   "collapsed": false
  },
  "outputs": [],
  "source": ""
 }
],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}}, "nbformat": 4, "nbformat_minor": 0}